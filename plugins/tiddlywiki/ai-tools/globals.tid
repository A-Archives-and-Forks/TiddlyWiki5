title: $:/plugins/tiddlywiki/ai-tools/globals
tags: $:/tags/Global

\function default-llm-completion-server()
[all[shadows+tiddlers]tag[$:/tags/AI/CompletionServer]sort[caption]first[]]
\end

<!--
Action procedure to retrieve an LLM completion, given the following parameters:
conversationTitle - Title of the tiddler containing the conversation
resultTitlePrefix - Prefix of the tiddler to be used for saving the result. If the tiddler already exists then a number will be added repeatedly until the resulting title is unique
resultTags - Tags to be applied to the result tiddler
statusTitle - Optional title of a tiddler to which the status of the request will be bound: "pending", "complete", "error"
completionServer - Optional URL of server
-->
\procedure get-llm-completion(conversationTitle,resultTitlePrefix,resultTags,statusTitle,completionServer)
<$let
	completionServer={{{ [<completionServer>!is[blank]else<default-llm-completion-server>] }}}
>
	<$importvariables filter="[<completionServer>]">
		<$wikify name="json" text=<<json-prompt>>>
			<$action-log message="get-llm-completion"/>
			<$action-log/>
			<$action-sendmessage
				$message="tm-http-request"
				url={{{ [<completionServer>get[url]] }}}
				body=<<json>>
				header-content-type="application/json"
				bearer-auth-token-from-store="openai-secret-key"
				method="POST"
				oncompletion=<<completion-callback>>
				bind-status=<<statusTitle>>
				var-resultTitlePrefix=<<resultTitlePrefix>>
				var-resultTags=<<resultTags>>
			/>
		</$wikify>
	</$importvariables>
</$let>
\end get-llm-completion
